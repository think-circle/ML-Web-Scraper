{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2> Domain.com.au Web Scraping</h2>\n",
    "                             <img src=\"http://www.domain.com.au/Content/Files/misc/domainLogoHead.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML extraction & Parsin\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import math\n",
    "import os\n",
    "from constants import Brisbane_suburbs,Melbourne_suburbs,Sydney_suburbs,Adelaide_suburbs,Perth_suburbs\n",
    "\n",
    "\n",
    "\n",
    "# Calculate Latitude & Longitude\n",
    "from geopy.geocoders import Nominatim\n",
    "# Calculate Distance from Latitude & Longitude\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import emailsend\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "# Change the index to change the city\n",
    "city_list = ['Sydney','Melbourne','Brisbane','Adelaide','Perth']\n",
    "city = city_list[3]\n",
    "if city == 'Sydney':\n",
    "    suburbs_list = Sydney_suburbs\n",
    "elif city == 'Melbourne':\n",
    "    suburbs_list = Melbourne_suburbs\n",
    "elif city == 'Brisbane':\n",
    "    suburbs_list = Brisbane_suburbs\n",
    "elif city == 'Adelaide':\n",
    "    suburbs_list = Adelaide_suburbs\n",
    "elif city == 'Perth':\n",
    "    suburbs_list = Perth_suburbs\n",
    "\n",
    "\n",
    "\n",
    "print(f\"CHOSEN CITY: {city}\")\n",
    "if not os.path.exists(f\"../MLrealestate/data/{city}/\"):\n",
    "    os.mkdir(f\"../MLrealestate/data/{city}/\")\n",
    "print(suburbs_list)\n",
    "for suburb in suburbs_list:\n",
    "    urls.append(f\"https://www.domain.com.au/sold-listings/{suburb}/?excludepricewithheld=1&landsize=10-any&ssubs=0&page=\")\n",
    "\n",
    "house_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API CALL VIA PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    max_pages = 50\n",
    "    for x in range(1,max_pages+1):\n",
    "        full_url = 'https://api.proxycrawl.com/?token=QviEcDJvtDVu2Jwa2GwbiQ&url=' +urllib.parse.quote_plus(url+str(x))\n",
    "        print(full_url)\n",
    "        html_text = requests.get(full_url).text\n",
    "        soup = BeautifulSoup(html_text,'lxml')\n",
    "        if x ==1:\n",
    "            try:\n",
    "                max_pages = math.ceil(int(soup.find(attrs = {'data-testid':'summary'}).text.split(' ')[0])/20)\n",
    "                print(str(max_pages) + ' is the number of pages found')\n",
    "                if max_pages > 50:\n",
    "                    print(str(max_pages)+ ' is the number of max pages found but we are capping it to 50')\n",
    "                    max_pages = 50\n",
    "            except:\n",
    "                max_pages = 2\n",
    "        if x > max_pages:\n",
    "            break\n",
    "                \n",
    "            \n",
    "        houses = soup.find_all('li',class_= 'css-1qp9106')\n",
    "\n",
    "        for house in houses:\n",
    "\n",
    "            # Extract Data Sold & Method of Sale\n",
    "            date_method = house.find('span', class_='css-1nj9ymt').text\n",
    "            date_method_split = date_method.split(\" \")\n",
    "            date = f\"{date_method_split[-3]} {date_method_split[-2]} {date_method_split[-1]}\"\n",
    "            if \"auction\" in date_method:\n",
    "                method = 'auction'\n",
    "            elif \"private treaty\" in date_method:\n",
    "                method = 'private treaty'\n",
    "            else:\n",
    "                method = 'Another Method'\n",
    "\n",
    "            # Extract Address details\n",
    "            try:\n",
    "    \n",
    "                street = house.find('span', class_='css-iqrvhs',attrs={'data-testid': 'address-line1'}).text.replace(',','')\n",
    "                \n",
    "            except:\n",
    "                print('ISSUE FOUND WITH STREET')\n",
    "                street = 'No Street Found'\n",
    "            \n",
    "            try:\n",
    "                 address = house.find('span', class_='css-iqrvhs',attrs={'data-testid': 'address-line2'}).text\n",
    "                 address_split = address.split(' ')\n",
    "                 postcode = address_split[-1]\n",
    "                 state = address_split[-2]\n",
    "                 if len(address_split) == 4:\n",
    "                    suburb = f\"{address_split[0]} {address_split[1]}\"\n",
    "                 elif len(address_split) == 5:\n",
    "                    suburb = f\"{address_split[0]} {address_split[1]} {address_split[2]}\"\n",
    "                 else:\n",
    "                    suburb = address_split[0]\n",
    "                \n",
    "            except:\n",
    "                print('ISSUE FOUND WITH ADDRESS')\n",
    "            \n",
    "               \n",
    "            \n",
    "\n",
    "            \n",
    "            price = house.find('p', class_='css-mgq8yx').text.replace(' price from APM PriceFinder','').replace('$','').replace(',','')\n",
    "            type = house.find('span', class_='css-693528').text.replace('/ Unit / Flat','')\n",
    "\n",
    "            try:\n",
    "                features = house.find('div', class_ ='css-18biwo', attrs = {'data-testid':'property-features-wrapper'})\n",
    "                bedrooms = features.span.span.text[0]\n",
    "                if bedrooms == '−' or bedrooms is None:\n",
    "                    bedrooms = 0\n",
    "                bathrooms = features.span.next_sibling.span.text[0]\n",
    "                if bathrooms == '−' or bathrooms is None:\n",
    "                    bathrooms = 1\n",
    "                cars = features.span.next_sibling.next_sibling.span.text[0]\n",
    "                if cars == '−':\n",
    "                    cars = 0\n",
    "                if len(list(features.children)) == 4:\n",
    "                    area = features.span.next_sibling.next_sibling.next_sibling.span.text\n",
    "                else:\n",
    "                    area = 0\n",
    "            except:\n",
    "                bedrooms = 0\n",
    "                bathrooms = 0\n",
    "                cars = 0\n",
    "                area = 0\n",
    "                print(f\"No features found for {street} {address}\")\n",
    "\n",
    "            agent = house.find('div', class_='css-6yavch',attrs={'data-testid':'listing-card-lazy-image'})\n",
    "            if agent is None:\n",
    "                agent = 'UNKNOWN'\n",
    "            elif agent.img['alt'][0] == 'P':\n",
    "                agent = 'UNKNOWN'\n",
    "            else:\n",
    "                agent = agent.img['alt'].replace('Logo for ','')\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            house_details = {\n",
    "                'Street' : street,\n",
    "                'Address' : address,\n",
    "                'Suburb' : suburb,\n",
    "                'State' : state,\n",
    "                'Postcode' : postcode,\n",
    "                'Type' : type,\n",
    "                'Date': date,\n",
    "                'Method' : method,\n",
    "                'Price' : price,\n",
    "                'Bedrooms': bedrooms,\n",
    "                'Bathrooms': bathrooms,\n",
    "                'Cars' : cars,\n",
    "                'Area' : area,\n",
    "                'Agent' : agent\n",
    "            }\n",
    "            if (bedrooms == 0 and bathrooms == 0 and cars == 0 and area == 0) or street == 'No Street Found':\n",
    "                print(f\"{street} {address} house was NOT added\")\n",
    "            else:\n",
    "                house_list.append(house_details)\n",
    "               \n",
    "        print(str(len(house_list))+' houses added so far')\n",
    "        if len(house_list) > 1000:\n",
    "            df = pd.DataFrame(house_list)\n",
    "            df.to_csv(f\"../MLrealestate/data/{city}/{city}_raw.csv\",mode='a', header = False, index = False)\n",
    "            house_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING PANDAS DF TO CSV. PLEASE NOTE: WE ARE APPENDING TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame(house_list)\n",
    "df.to_csv(f\"../MLrealestate/data/{city}/{city}_raw.csv\",mode='a', header = True, index = False)\n",
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Latitude & Longitude columns from address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(f\"../MLrealestate/data/{city}/{city}_raw.csv\")\n",
    "\n",
    "def get_coordinates(street, suburb):\n",
    "    loc = Nominatim(user_agent=\"GetLoc\")\n",
    "\n",
    "    try:\n",
    "        if {street} == 'No Street Found':\n",
    "            getLoc = loc.geocode(f\"{suburb},Australia\")\n",
    "        else:\n",
    "            getLoc = loc.geocode(f\"{street},{suburb},Australia\")\n",
    "        lat = getLoc.latitude\n",
    "        long = getLoc.longitude\n",
    "    except:\n",
    "        try:\n",
    "            getLoc = loc.geocode(f\"{suburb},Australia\")\n",
    "            lat = getLoc.latitude\n",
    "            long = getLoc.longitude\n",
    "        except:\n",
    "            print(f\"{street},{suburb},Australia was not able to find lat & long\")\n",
    "            lat = -37.7618477\n",
    "            long = 144.9805318\n",
    "    return lat,long\n",
    "\n",
    "\n",
    "vect_get_coordinates = np.vectorize(get_coordinates)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df.index),1000):\n",
    "    df_seg = df[i:i+1000]\n",
    "    df_seg['Latitude'], df_seg['Longitude']  = vect_get_coordinates(df_seg.Street, df_seg.Address)\n",
    "    df_seg.to_csv(f\"../MLrealestate/data/{city}/{city}_latlon.csv\",mode='a',header = False,index=False)\n",
    "    print(f\"PROCESSED: {len(df_seg)} RECORDS OUT OF TOTAL {len(df.index)}\")\n",
    "    print(f\"PROGRESS: {len(df_seg)/len(df.index)} % COMPLETED\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE DISTANCE FROM CITY by vectorization function and using Latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(f\"../data/{city}/{city}_latlon.csv\")\n",
    "\n",
    "suburb_of_city = f\"{city.split('-')[0]}\"\n",
    "la2,lo2 = get_coordinates('No Street Found', suburb_of_city)\n",
    "\n",
    "\n",
    "def calc_distance(la1,lo1):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(la1)\n",
    "    lon1 = radians(lo1)\n",
    "    lat2 = radians(la2)\n",
    "    lon2 = radians(lo2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance\n",
    "   \n",
    "\n",
    "vec_cal_distance = np.vectorize(calc_distance)\n",
    "df['Distance']  = vec_cal_distance(df.Latitude, df.Longitude)\n",
    "df.to_csv(f\"../data/{city}/{city}_distance.csv\",header = True,index=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up Area by removing commas,m2, and converting Ha to m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../MLrealestate/data/{city}/{city}_distance.csv\")\n",
    "\n",
    "def convert_area(area):\n",
    "    if ',' in area:\n",
    "        area = area.replace(',','')\n",
    "    if 'm²' in area:\n",
    "        area = area.replace('m²','')\n",
    "    if 'ha' in area:\n",
    "        area = 10000*float(area.replace('ha',''))\n",
    "    return float(area)\n",
    "   \n",
    "\n",
    "vec_convert_area = np.vectorize(convert_area)\n",
    "df['Area']  = vec_convert_area(df.Area)\n",
    "\n",
    "\n",
    "df.to_csv(f\"../MLrealestate/data/{city}/{city}_area.csv\",header = True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Email of the collected & transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emailsend.run(f\"../MLrealestate/data/{city}/{city}_distance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

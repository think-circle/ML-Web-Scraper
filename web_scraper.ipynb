{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2> Domain.com.au Web Scraping</h2>\n",
    "                             <img src=\"http://www.domain.com.au/Content/Files/misc/domainLogoHead.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML extraction & Parsin\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "# Calculate Latitude & Longitude\n",
    "from geopy.geocoders import Nominatim\n",
    "# Calculate Distance from Latitude & Longitude\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import emailsend\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SET GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHOSEN CITY: melbourne-region-vic\n"
     ]
    }
   ],
   "source": [
    "\n",
    "region_list = [\n",
    "'melbourne-region-vic',\n",
    "'sydney-region-nsw',\n",
    "'brisbane-region-qld',\n",
    "'adelaide-region-sa',\n",
    "'perth-metropolitan-eastern-suburbs-wa',\n",
    "'perth-metropolitan-western-suburbs-wa',\n",
    "'perth-metropolitan-northern-suburbs-wa',\n",
    "'perth-metropolitan-southern-suburbs-wa',\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "price_range_list = [\n",
    " '000000-150000',\n",
    "# '150000-200000',\n",
    "# '200000-250000',\n",
    "# '250000-300000',\n",
    "# '300000-350000',\n",
    "# '350000-400000',\n",
    "# '400000-450000',\n",
    "# '450000-500000',\n",
    "# '500000-550000',\n",
    "# '550000-600000',\n",
    "# '600000-650000',\n",
    "# '650000-700000',\n",
    "# '700000-750000',\n",
    "# '750000-800000',\n",
    "# '800000-850000',\n",
    "# '850000-900000',\n",
    "# '900000-950000',\n",
    "# '950000-1000000',\n",
    "# '1000000-1050000',\n",
    "# '1050000-1100000',\n",
    "# '1100000-1150000',\n",
    "# '1150000-1200000',\n",
    "# '1200000-1250000',\n",
    "# '1250000-1300000',\n",
    "# '1300000-1350000',\n",
    "# '1350000-1400000',\n",
    "# '1400000-1450000',\n",
    "# '1450000-1500000',\n",
    "# '1500000-1550000',\n",
    "# '1550000-1600000',\n",
    "# '1600000-1650000',\n",
    "# '1650000-1700000',\n",
    "# '1700000-1750000',\n",
    "# '1750000-1800000',\n",
    "# '1800000-1850000',\n",
    "# '1850000-1900000',\n",
    "# '1900000-1950000',\n",
    "# '1950000-2000000',\n",
    "# '2000000-2050000',\n",
    "# '2050000-2100000',\n",
    "# '2100000-2150000',\n",
    "# '2150000-2200000',\n",
    "# '2200000-2250000',\n",
    "# '2250000-2300000',\n",
    "# '2300000-2350000',\n",
    "# '2350000-2400000',\n",
    "# '2400000-2450000',\n",
    "# '2450000-2500000',\n",
    "# '2500000-2550000',\n",
    "# '2550000-2600000',\n",
    "# '2600000-2650000',\n",
    "# '2650000-2700000',\n",
    "# '2700000-2750000',\n",
    "# '2750000-2800000',\n",
    "# '2800000-2850000',\n",
    "# '2850000-2900000',\n",
    "# '2900000-2950000',\n",
    "# '2950000-3000000',\n",
    "# '3000000-3200000',\n",
    "# '3200000-3400000',\n",
    "# '3400000-3600000',\n",
    "# '3600000-3800000',\n",
    "# '3800000-4000000',\n",
    "# '4000000-4200000',\n",
    "# '4200000-4400000',\n",
    "# '4400000-4600000',\n",
    "# '4600000-4800000',\n",
    "# '4800000-5000000',\n",
    "# '5000000-5200000',\n",
    "# '5200000-5400000',\n",
    "# '5400000-5600000',\n",
    "# '5600000-5800000',\n",
    "# '5800000-6000000',\n",
    "# '6000000-6200000',\n",
    "]\n",
    "\n",
    "urls = []\n",
    "# Change the index to change the city\n",
    "region = region_list[0]\n",
    "\n",
    "\n",
    "city = {region}.split('-')[0].capitalise()\n",
    "print(f\"CHOSEN CITY: {city}\")\n",
    "for p_range in price_range_list:\n",
    "    urls.append(f\"https://www.domain.com.au/sold-listings/{region}/house/?price={p_range}&excludepricewithheld=1&landsize=1-any&ssubs=0&page=\")\n",
    "\n",
    "\n",
    "house_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API CALL VIA PROXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    max_pages = 50\n",
    "    for x in range(1,max_pages+1):\n",
    "        full_url = 'https://app.scrapingbee.com/api/v1/?api_key=T6K98ENA0TKGTK4BK6LU7JCATYMR52A6YXD0QGSYH5B0NGIOE4X5PUQ4LDEJK77YETEX3XORL6S1ITDB&url='+urllib.parse.quote_plus(url+str(x))\n",
    "        print(full_url)\n",
    "        html_text = requests.get(full_url).text\n",
    "        soup = BeautifulSoup(html_text,'lxml')\n",
    "        if x ==1:\n",
    "            max_pages = math.ceil(int(soup.find(attrs = {'data-testid':'summary'}).text.split(' ')[0])/20)\n",
    "            print(str(max_pages)+ ' is the number of max pages')\n",
    "            \n",
    "        houses = soup.find_all('li',class_= 'css-1qp9106')\n",
    "\n",
    "        for house in houses:\n",
    "\n",
    "            # Extract Data Sold & Method of Sale\n",
    "            date_method = house.find('span', class_='css-1nj9ymt').text\n",
    "            date_method_split = date_method.split(\" \")\n",
    "            date = f\"{date_method_split[-3]} {date_method_split[-2]} {date_method_split[-1]}\"\n",
    "            if \"auction\" in date_method:\n",
    "                method = 'auction'\n",
    "            elif \"private treaty\" in date_method:\n",
    "                method = 'private treaty'\n",
    "            else:\n",
    "                method = 'Another Method'\n",
    "\n",
    "            # Extract Address details\n",
    "            try:\n",
    "    \n",
    "                street = house.find('span', class_='css-iqrvhs',attrs={'data-testid': 'address-line1'}).text.replace(',','')\n",
    "                \n",
    "            except:\n",
    "                print('ISSUE FOUND WITH STREET')\n",
    "                street = 'No Street Found'\n",
    "            \n",
    "            try:\n",
    "                 address = house.find('span', class_='css-iqrvhs',attrs={'data-testid': 'address-line2'}).text\n",
    "                 address_split = address.split(' ')\n",
    "                 postcode = address_split[-1]\n",
    "                 state = address_split[-2]\n",
    "                 if len(address_split) == 4:\n",
    "                    suburb = f\"{address_split[0]} {address_split[1]}\"\n",
    "                 elif len(address_split) == 5:\n",
    "                    suburb = f\"{address_split[0]} {address_split[1]} {address_split[2]}\"\n",
    "                 else:\n",
    "                    suburb = address_split[0]\n",
    "                \n",
    "            except:\n",
    "                print('ISSUE FOUND WITH ADDRESS')\n",
    "            \n",
    "               \n",
    "            \n",
    "\n",
    "            \n",
    "            price = house.find('p', class_='css-mgq8yx').text.replace(' price from APM PriceFinder','').replace('$','').replace(',','')\n",
    "            type = house.find('span', class_='css-693528').text.replace('/ Unit / Flat','')\n",
    "\n",
    "            try:\n",
    "                features = house.find('div', class_ ='css-18biwo', attrs = {'data-testid':'property-features-wrapper'})\n",
    "                bedrooms = features.span.span.text[0]\n",
    "                if bedrooms == '−' or bedrooms is None:\n",
    "                    bedrooms = 0\n",
    "                bathrooms = features.span.next_sibling.span.text[0]\n",
    "                if bathrooms == '−' or bathrooms is None:\n",
    "                    bathrooms = 1\n",
    "                cars = features.span.next_sibling.next_sibling.span.text[0]\n",
    "                if cars == '−':\n",
    "                    cars = 0\n",
    "                if len(list(features.children)) == 4:\n",
    "                    area = features.span.next_sibling.next_sibling.next_sibling.span.text\n",
    "                else:\n",
    "                    area = 0\n",
    "            except:\n",
    "                bedrooms = 0\n",
    "                bathrooms = 0\n",
    "                cars = 0\n",
    "                area = 0\n",
    "                print(f\"No features found for {street} {address}\")\n",
    "\n",
    "            agent = house.find('div', class_='css-6yavch',attrs={'data-testid':'listing-card-lazy-image'})\n",
    "            if agent is None:\n",
    "                agent = 'UNKNOWN'\n",
    "            elif agent.img['alt'][0] == 'P':\n",
    "                agent = 'UNKNOWN'\n",
    "            else:\n",
    "                agent = agent.img['alt'].replace('Logo for ','')\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "            house_details = {\n",
    "                'Street' : street,\n",
    "                'Address' : address,\n",
    "                'Suburb' : suburb,\n",
    "                'State' : state,\n",
    "                'Postcode' : postcode,\n",
    "                'Type' : type,\n",
    "                'Date': date,\n",
    "                'Method' : method,\n",
    "                'Price' : price,\n",
    "                'Bedrooms': bedrooms,\n",
    "                'Bathrooms': bathrooms,\n",
    "                'Cars' : cars,\n",
    "                'Area' : area,\n",
    "                'Agent' : agent\n",
    "            }\n",
    "            if (bedrooms == 0 and bathrooms == 0 and cars == 0 and area == 0) or street == 'No Street Found':\n",
    "                print(f\"{street} {address} house was NOT added\")\n",
    "            else:\n",
    "                house_list.append(house_details)\n",
    "               \n",
    "        print(str(len(house_list))+' houses added so far')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING PANDAS DF TO CSV. PLEASE NOTE: WE ARE APPENDING TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(house_list)\n",
    "if not os.path.exists(f\"../data/{city}/\"):\n",
    "    os.mkdir(f\"../data/{city}/\")\n",
    "df.to_csv(f\"../data/{city}/{city}_raw.csv\",header = True, index = False)\n",
    "df.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Latitude & Longitude columns from address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(f\"../data/{city}/{city}_raw.csv\")\n",
    "\n",
    "def get_coordinates(street, suburb):\n",
    "    loc = Nominatim(user_agent=\"GetLoc\")\n",
    "\n",
    "    try:\n",
    "        if {street} == 'No Street Found':\n",
    "            getLoc = loc.geocode(f\"{suburb},Australia\")\n",
    "        else:\n",
    "            getLoc = loc.geocode(f\"{street},{suburb},Australia\")\n",
    "        lat = getLoc.latitude\n",
    "        long = getLoc.longitude\n",
    "    except:\n",
    "        try:\n",
    "            getLoc = loc.geocode(f\"{suburb},Australia\")\n",
    "            lat = getLoc.latitude\n",
    "            long = getLoc.longitude\n",
    "        except:\n",
    "            print(f\"{street},{suburb},Australia was not able to find lat & long\")\n",
    "            lat = -37.7618477\n",
    "            long = 144.9805318\n",
    "    return lat,long\n",
    "\n",
    "\n",
    "vect_get_coordinates = np.vectorize(get_coordinates)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(df.index),1000):\n",
    "    df_seg = df[i:i+1000]\n",
    "    df_seg['Latitude'], df_seg['Longitude']  = vect_get_coordinates(df_seg.Street, df_seg.Address)\n",
    "    df_seg.to_csv(f\"../data/{city}/{city}_latlon.csv\",mode='a',header = False,index=False)\n",
    "    print(f\"PROCESSED: {len(df_seg)} RECORDS OUT OF TOTAL {len(df.index)}\")\n",
    "    print(f\"PROGRESS: {len(df_seg)/len(df.index)} % COMPLETED\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALCULATE DISTANCE FROM CITY by vectorization function and using Latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(f\"../data/{city}/{city}_latlon.csv\")\n",
    "\n",
    "suburb_of_city = f\"{city.split('-')[0]}\"\n",
    "la2,lo2 = get_coordinates('No Street Found', suburb_of_city)\n",
    "\n",
    "\n",
    "def calc_distance(la1,lo1):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(la1)\n",
    "    lon1 = radians(lo1)\n",
    "    lat2 = radians(la2)\n",
    "    lon2 = radians(lo2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance\n",
    "   \n",
    "\n",
    "vec_cal_distance = np.vectorize(calc_distance)\n",
    "df['Distance']  = vec_cal_distance(df.Latitude, df.Longitude)\n",
    "df.to_csv(f\"../data/{city}/{city}_distance.csv\",header = True,index=False)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../data/{city}/{city}_distance.csv\")\n",
    "\n",
    "def convert_area(area):\n",
    "    # approximate radius of earth in km\n",
    "    if ',' in area:\n",
    "        area = area.replace(',','')\n",
    "    if 'm²' in area:\n",
    "        area = area.replace('m²','')\n",
    "    if 'ha' in area:\n",
    "        area = 10000*float(area.replace('ha',''))\n",
    "    return area\n",
    "   \n",
    "\n",
    "vec_convert_area = np.vectorize(convert_area)\n",
    "df['Area']  = vec_convert_area(df.Area)\n",
    "\n",
    "\n",
    "df.to_csv(f\"../data/{city}/{city}_area.csv\",header = True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Email of the collected & transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emailsend.run(f\"../data/{city}/{city}_distance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
